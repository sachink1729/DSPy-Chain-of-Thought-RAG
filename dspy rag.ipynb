{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Chain of thought of RAG Pipeline using Ollama x llama2, Qdrant and DSPy.\n",
    "\n",
    "#### Author: Sachin Khandewal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dspy-ai\n",
    "# !pip install qdrant-client\n",
    "# !pip install ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\new\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "\n",
    "# Load the dataset.\n",
    "dataset = HotPotQA(train_seed=1, train_size=1000)\n",
    "\n",
    "# Tell DSPy that the 'question' field is the input. Any other fields are labels and/or metadata.\n",
    "dataset = [x.with_inputs('question') for x in dataset.train]\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?', 'answer': 'Operation Citadel'}) (input_keys={'question'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is a block away from the arena where the Baltimore Blast play their games?',\n",
       " 'Baltimore Convention Center')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[300].question, dataset[300].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the retriever using Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-20 20:03:08.472\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfastembed.embedding\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[33m\u001b[1mDefaultEmbedding, FlagEmbedding, JinaEmbedding are deprecated. Use TextEmbedding instead.\u001b[0m\n",
      "100%|██████████| 77.7M/77.7M [00:23<00:00, 3.35MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from dspy.retrieve.qdrant_rm import QdrantRM\n",
    "from qdrant_client import QdrantClient\n",
    " \n",
    "qdrant_client = QdrantClient(\":memory:\")  # loads in memory for this session\n",
    "\n",
    "docs = [x.question + \" -> \" + x.answer for x in dataset]\n",
    "\n",
    "ids = list(range(0,len(docs)))\n",
    "\n",
    "\n",
    "qdrant_client.add(\n",
    "    collection_name=\"hotpotqa\",\n",
    "    documents=docs,\n",
    "    ids=ids\n",
    "    )\n",
    "\n",
    "\n",
    "qdrant_retriever_model = QdrantRM(\"hotpotqa\", qdrant_client, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Ollama model\n",
    "\n",
    "Pre-requisites: should have downlaoded the Ollama application from: https://ollama.com/download/windows\n",
    "\n",
    "For Windows you can follow these steps:\n",
    "1) To download it, go to: Download Ollama on Windows. \n",
    "2) Install it on your system.\n",
    "3) After installing, you can open the command prompt and type “ollama pull llama2”, which will download the latest quantized image for Llama2; by default, it pulls a 7B model.\n",
    "4) You will see the Ollama icon in your hidden icons, which means that you can run Ollama models now!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "ollama_model = dspy.OllamaLocal(model=\"llama2\",model_type='text',\n",
    "                                max_tokens=350,\n",
    "                                temperature=0.7,\n",
    "                                top_p=0.9, frequency_penalty=1.17, top_k=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out one example before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Interstellar is a 2014 science fiction film directed by Christopher Nolan that follows a group of astronauts on a mission to travel through wormholes in search of a new habitable planet for humanity. Here is the general plot outline:\\n\\nIn the near future, Earth is facing an unprecedented crisis as crops are failing and food supplies are running low. The world's top scientists, led by Dr. Josep Mendes (Michael Caine), are unable to find a solution to this problem, which threatens the survival of humanity.\\n\\nEnter Cooper (Matthew McConaughey), a former NASA pilot who is recruited for a dangerous mission through wormholes in search of a new habitable planet. Cooper's daughter Murph (Jessica Chastain) is a brilliant young girl who has been struggling to understand the equations that could potentially save Earth, and her father's journey becomes crucial to her research.\\n\\nCooper and his team, which includes Dr. Stone (Stephen Henderson), Amelia Brand (Anne Hathaway), and Romilly (David Gyasi), embark on a dangerous journey through the wormholes, encountering various obstacles along the way. They also encounter strange occurrences that challenge their understanding of time and space.\\n\\nAs Cooper travels through the wormholes, he experiences events in different dimensions and timelines, which affect his perception of reality. Back on Earth, Murph continues her research and discovers a hidden message from her father that could hold the key to saving humanity.\\n\\nThe film's\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama_model(\"tell me about interstellar's plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Top Passages from the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 passages for question: What was a previous unoffical name for the high performance variant of Audi's compact executive car? \n",
      " ------------------------------ \n",
      "\n",
      "1] What was a previous unoffical name for the high performance variant of Audi's compact executive car? -> Audi Ur-S4 \n",
      "\n",
      "2] What car models used the same Saxomat clutch as the automobiles produced by former East German auto maker VEB Sachsenring Automobilwerke Zwickau in Zwickau, Saxony? -> Fiat 1800, Lancia Flaminia, Saab 93, Borgward Isabella, Goliath/Hansa 1100, Auto Union 1000, Ford Taunus \n",
      "\n",
      "3] William Sachiti is the founder of the company that is a UK competitor to the major automaker based in what city? -> Palo Alto \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "dspy.settings.configure(rm=qdrant_retriever_model, lm=ollama_model)\n",
    "\n",
    "dev_example = dataset[100]\n",
    "\n",
    "def get_top_passages(question):\n",
    "    retrieve = dspy.Retrieve(k=3)\n",
    "    topK_passages = retrieve(question,k=3).passages\n",
    "    print(f\"Top {retrieve.k} passages for question: {question} \\n\", '-' * 30, '\\n')\n",
    "    for idx, passage in enumerate(topK_passages):\n",
    "        print(f'{idx+1}]', passage, '\\n')\n",
    "\n",
    "get_top_passages(dev_example.question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Signatures for Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may or maynot contain relevant facts or answer keywords\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"an answer between 10 to 20 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GenerateAnswer(context=\"My name is sachin and I like writing blogs\", question=\"What is my name?\", answer=\"Sachin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseModel.model_construct of GenerateAnswer(context, question -> answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may or maynot contain relevant facts or answer keywords', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'an answer between 10 to 20 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(ga.model_construct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DSPy CoT Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the RAG object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompiled_rag = RAG()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some datapoints from which we can ask CoT questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Example({'question': \"Who has been on a British television music competition show and was was most popular in the 80's with the pop band 'Culture Club'?\", 'answer': \"George Alan O'Dowd\"}) (input_keys={'question'}),\n",
       " Example({'question': \"What was a previous unoffical name for the high performance variant of Audi's compact executive car?\", 'answer': 'Audi Ur-S4'}) (input_keys={'question'}),\n",
       " Example({'question': 'Which is taller, the Empire State Building or the Bank of America Tower?', 'answer': 'The Empire State Building'}) (input_keys={'question'}))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[91],dataset[100],dataset[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run the queries now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, George Alan O'Dowd was not the most popular in the late 2000s with his rock band.\n"
     ]
    }
   ],
   "source": [
    "my_question = \"Was George Alan O'Dowd the most popular in the late 2000s with his rock band?\"\n",
    "# my_question = \"which segment of Audi's car was named as Ur-S4?\"\n",
    "# my_question = \"is Bank of America Tower taller than empire state building?\"\n",
    "\n",
    "# get_top_passages(my_question)\n",
    "\n",
    "response = uncompiled_rag(my_question)\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the prompt internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may or maynot contain relevant facts or answer keywords\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: an answer between 10 to 20 words\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Who has been on a British television music competition show and was was most popular in the 80's with the pop band 'Culture Club'? -> George Alan O'Dowd»\n",
      "[2] «Who was dubbed the father of the type of rock music that emerged from post-punk in the late 1970s? -> Brian Healy»\n",
      "[3] «Alan Forbes has done posters for an American rock band that formed in 1996 in what city in California? -> Palm Desert»\n",
      "\n",
      "Question: Was George Alan O'Dowd the most popular in the late 2000s with his rock band?\n",
      "\n",
      "Reasoning: Let's think step by step in order to Answer: No, George Alan O'Dowd was not the most popular in the late 2000s. He was active and popular in the 1980s with his pop band Culture Club.\n",
      "\n",
      "Answer:\u001b[32m No, George Alan O'Dowd was not the most popular in the late 2000s with his rock band.\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ollama_model.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADVANCED (Using teleprompters to train the CoT model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:44<00:00, 54.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "\n",
    "dataset_dev = [dataset[91],\n",
    "dataset[100],\n",
    "dataset[6]]\n",
    "\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Validation logic: check that the predicted answer is correct.\n",
    "# Also check that the retrieved context does actually contain that answer.\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM\n",
    "\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
    "\n",
    "# Compile!\n",
    "compiled_rag = teleprompter.compile(RAG(), dataset=dataset_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask any question you like to this simple RAG program.\n",
    "\n",
    "my_question = \"Was George Alan O'Dowd the most popular in the early 1980s with his pop band?\"\n",
    "# my_question = \"which segment of Audi's car was named as Ur-S4?\"\n",
    "# my_question = \"is Bank of America Tower taller than empire state building?\"\n",
    "\n",
    "# get_top_passages(my_question)\n",
    "\n",
    "# Get the prediction. This contains `pred.context` and `pred.answer`.\n",
    "pred = compiled_rag(my_question)\n",
    "\n",
    "# Print the contexts and the answer.\n",
    "print(f\"Question: {my_question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `context`, `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which is taller, the Empire State Building or the Bank of America Tower?\n",
      "Answer: The Empire State Building\n",
      "\n",
      "Question: What was a previous unoffical name for the high performance variant of Audi's compact executive car?\n",
      "Answer: Audi Ur-S4\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: ${context}\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Who has been on a British television music competition show and was was most popular in the 80's with the pop band 'Culture Club'? -> George Alan O'Dowd»\n",
      "[2] «The Fridge had booked such acts as the English singer and DJ who was the lead singer of what pop band? -> Culture Club»\n",
      "[3] «Celebration was recorded by the singer who was a leading presence when what cable channel premiered? -> MTV»\n",
      "\n",
      "Question: Who has been on a British television music competition show and was was most popular in the 80's with the pop band 'Culture Club'?\n",
      "\n",
      "Reasoning: Let's think step by step in order to Context: [1] «Who has been on a British television music competition show and was was most popular in the 80's with the pop band 'Culture Club'? -> George Alan O'Dowd» [2] «The Fridge had booked such acts as the English singer and DJ who was the lead singer of what pop band? -> Culture Club» [3] «Celebration was recorded by the singer who was a leading presence when what cable channel premiered? -> MTV» Question: Who has been on a British television music competition show and was was most popular in the 80's with the pop band 'Culture Club'? Reasoning: Let's think step by step in order to answer this question. We know from [1] that George Alan O'Dowd has been on a British television music competition show. From [2], we know that Culture Club was a popular pop band in the 80's. Therefore, the answer must be George Alan O'Dowd, who was the lead singer of Culture Club.\n",
      "\n",
      "Answer: George Alan O'Dowd\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Who has been on a British television music competition show and was was most popular in the 80's with the pop band 'Culture Club'? -> George Alan O'Dowd»\n",
      "[2] «The Fridge had booked such acts as the English singer and DJ who was the lead singer of what pop band? -> Culture Club»\n",
      "[3] «What singer, best known for his recording of the song \"Raindrops Keep Fallin' on My Head\", had his single \"Most of All\" reach #2 on the \"Billboard\" Adult Contemporary singles chart in 1970? -> B. J. Thomas»\n",
      "\n",
      "Question: Was George Alan O'Dowd the most popular in the late 1980s with his pop band?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m Context: [1] «Who has been on a British television music competition show and was was most popular in the 80's with the pop band 'Culture Club'? -> George Alan O'Dowd» [2] «The Fridge had booked such acts as the English singer and DJ who was the lead singer of what pop band? -> Culture Club» [3] «What singer, best known for his recording of the song \"Raindrops Keep Fallin' on My Head\", had his single \"Most of All\" reach #2 on the \"Billboard\" Adult Contemporary singles chart in 1970? -> B. J. Thomas»\n",
      "Question: Was George Alan O'Dowd the most popular in the late 1980s with his pop band?\n",
      "Reasoning: Let's think step by step in order to answer this question. We know from [1] that George Alan O'Dowd was the lead singer of Culture Club, which was a popular pop band in the 80's. However, we also know from [3] that B. J. Thomas was more popular than George Alan O'Dowd in the late 70's and early 80's. Therefore, the answer must be no, George Alan O'Dowd was not the most popular pop band leader in the late 1980s.\n",
      "\n",
      "Answer: No\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ollama_model.inspect_history(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
